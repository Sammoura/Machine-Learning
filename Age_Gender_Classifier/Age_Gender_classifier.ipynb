{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Age_Gender_classifier.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rDSaqP4RY7Gd","colab_type":"code","colab":{}},"cell_type":"code","source":["# [1]\n","# Age Classifier with stratified Kfold cross validation, UTK\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def stratified_sampling(X, y, test_size, random_state):\n","    # apply Scikit stratified sampling\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n","    for train_index, test_index in sss.split(X, y):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","    return X_train, X_test, y_train, y_test\n","  \n","print(\"###############<< Age Classifier >>###############\\n\")\n","start_time = time.time()\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","\n","# Initialize GoogleDriveFile instance with file id.\n","data_file_64 = drive.CreateFile({'id': '1BE5HdE_mYkd6XjJ7e_pY6m3nfGaRZ87_'})\n","data_file_64.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_128 = drive.CreateFile({'id': '1Tsf7XwB09dUZVXSmlO81Fw3lumUnRiNb'})\n","# data_file_128.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_200 = drive.CreateFile({'id': '1hTnC0V1-P0sT-nLhl5JK7ETMpXdL9zgd'})\n","# data_file_200.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# train_data_128_adience = drive.CreateFile({'id': '17uW_i5i4QIsbka_QPE424B2OyZgKE7jV'})\n","# train_data_128_adience.GetContentFile('Adience_train_data.mat') \n","\n","# test_data_128_adience = drive.CreateFile({'id': '1nFm9J_rmZpI6ToVBeLrp1GPgXWVnamZT'})\n","# test_data_128_adience.GetContentFile('Adience_test_data.mat') \n","\n","num_cats = 8 # number of age categories (0, 4), [4, 8), [8, 15), [15, 25), [25, 38), [38, 48), [48, 60), 60+\n","sz = 64     # image dimension\n","print('UTK dataset: ', sz, \" ===> Age Classification\")\n","data = scipy.io.loadmat('UTKdata')\n","X = data['X']\n","y = data['y_age'][0]\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","input_shape = (sz, sz, 3)\n","\n","X, X_test, y, y_test = stratified_sampling(X, y, test_size=0.15, random_state=37)\n","y_test = np_utils.to_categorical(y_test, num_cats)\n","\n","print(\"Train size = \", y.shape[0]) \n","print(\"Test size = \", y_test.shape[0])\n","\n","print('=========<< [3] Model build & train >>=========')\n","\n","# create model\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","model = Sequential()\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","# print(model.summary())\n","\n","# # load weigts trained on a previus training session\n","# last_weight_file = drive.CreateFile({'id': '1-2AueMt5zJ9OMA-pgETHZExlA5s0cCzI'}) # age\n","# last_weight_file.GetContentFile('last_weights.mat')\n","# model.load_weights('last_weights.mat')\n","\n","# Compile model\n","model.compile(optimizer=SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# define 10-fold cross validation\n","kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=37)\n","cvscores = []\n","\n","# loop over folds and aggregate metrics\n","fold_ctr = 1\n","for train, vald in kfold.split(X, y):\n","  y1 = np_utils.to_categorical(y, num_cats)\n","  # Fit the model\n","  model.fit(X[train], y1[train], epochs=2, batch_size=30, verbose=0)\n","\n","  # evaluate the model\n","  scores = model.evaluate(X[vald], y1[vald], verbose=0)\n","  print(\"Fold :%d    %s: %.2f%%\" % (fold_ctr, model.metrics_names[1], scores[1]*100))\n","  fold_ctr = fold_ctr + 1\n","  cvscores.append(scores[1] * 100)\n","  \n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","\n","print('=========<< [4] Predict >>=========')\n","\n","predictions = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","# Save Keras ModelCheckpoints on google drive\n","\n","# save model weights\n","id_64 = '1HQ2-ZE4wmY6KHy5DRHLAsEw-R4UyjgmV'\n","id_128 = '1nkk_tv_e4aVM_DXS5152smOm3vN55ZZZ'\n","\n","fname = 'model_weights_age_strat_Kfold.h5'\n","model.save_weights(fname)\n","weights_file_aug = drive.CreateFile({'title' : fname, \n","                   'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","weights_file_aug.SetContentFile(fname)\n","weights_file_aug.Upload()\n","drive.CreateFile({'id': weights_file_aug.get('id')})\n","\n","# save whole model (architecture + weights + optimizer state)\n","fname1 = 'model_age_stratified_Kfold.h5'\n","model.save(fname1)\n","model_file = drive.CreateFile({'title' : fname1, \n","                  'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","model_file.SetContentFile(fname1)\n","model_file.Upload()\n","drive.CreateFile({'id': model_file.get('id')})\n","\n","y_pred = model.predict_classes(x=X_test, batch_size=None, verbose=0, steps=None)\n","y_test = np.argmax(y_test, 1)\n","\n","class_names = ['0-3', '4-7', '8-14', '15-24', '25-37', '38-47', '48-59', '60-']\n","\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Age Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Age Normalized confusion matrix')\n","\n","plt.show()\n","print(\"\\nelapsed_time = \", (time.time() - start_time)/60, \" minutes\")\n","\n","\n","# References:\n","#     [1] Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n","#     [2] https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JwZS0nH6aph4","colab_type":"code","colab":{}},"cell_type":"code","source":["# [2]\n","# Gender Classifier with stratified Kfold cross validation, UTK\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","  \n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def stratified_sampling(X, y, test_size, random_state):\n","    # apply Scikit stratified sampling\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n","    for train_index, test_index in sss.split(X, y):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","    return X_train, X_test, y_train, y_test\n","\n","print(\"****************<< Gender Classifier >>****************\\n\")\n","start_time = time.time()\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","\n","# Initialize GoogleDriveFile instance with file id.\n","data_file = drive.CreateFile({'id': '1BE5HdE_mYkd6XjJ7e_pY6m3nfGaRZ87_'})      # input image (64, 64, 3)\n","# data_file = drive.CreateFile({'id': '1Tsf7XwB09dUZVXSmlO81Fw3lumUnRiNb'})    # input image (128, 128, 3)\n","data_file.GetContentFile('UTKdata.mat')\n","\n","num_cats = 2\n","sz = 64\n","\n","data = scipy.io.loadmat('UTKdata')\n","X = data['X']\n","y = data['y_gender'][0]\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","input_shape = (sz, sz, 3)\n","X, X_test, y, y_test = stratified_sampling(X, y, test_size=0.15, random_state=37)\n","y_test = np_utils.to_categorical(y_test, num_cats)\n","\n","print(\"Train size = \", y.shape[0]) \n","print(\"Test size = \", y_test.shape[0])\n","\n","print('=========<< [3] Model build & train >>=========')\n","\n","# create model\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","model = Sequential()\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","# print(model.summary())\n","\n","# # load weigts trained on a previus training session\n","# last_weight_file = drive.CreateFile({'id': '1QRUpGK-kEbw1zylZhpEjXx-ApxBw3LGA'}) # age\n","# last_weight_file.GetContentFile('last_weights.mat')\n","# model.load_weights('last_weights.mat')\n","\n","# Compile model\n","model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# define 10-fold cross validation\n","kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=37)\n","cvscores = []\n","\n","# loop over folds and aggregate metrics\n","fold_ctr = 1\n","for train, vald in kfold.split(X, y):\n","  y1 = np_utils.to_categorical(y, num_cats)\n","  # Fit the model\n","  model.fit(X[train], y1[train], epochs=2, batch_size=30, verbose=0)\n","\n","  # evaluate the model\n","  scores = model.evaluate(X[vald], y1[vald], verbose=0)\n","  print(\"Fold :%d  %s = %.2f%%\"  % (fold_ctr, model.metrics_names[1], scores[1]*100))\n","  fold_ctr = fold_ctr + 1\n","  cvscores.append(scores[1] * 100)\n","  \n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","\n","print('=========<< [4] Predict >>=========')\n","\n","predictions = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","# Save Keras ModelCheckpoints on google drive\n","\n","# save model weights\n","id_64 = '1HQ2-ZE4wmY6KHy5DRHLAsEw-R4UyjgmV'\n","id_128 = '1nkk_tv_e4aVM_DXS5152smOm3vN55ZZZ'\n","\n","fname = 'model_weights_gender_strat_Kfold.h5'\n","model.save_weights(fname)\n","weights_file_aug = drive.CreateFile({'title' : fname, \n","                   'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","weights_file_aug.SetContentFile(fname)\n","weights_file_aug.Upload()\n","drive.CreateFile({'id': weights_file_aug.get('id')})\n","\n","# save whole model (architecture + weights + optimizer state)\n","fname1 = 'model_gender_stratified_Kfold.h5'\n","model.save(fname1)\n","model_file = drive.CreateFile({'title' : fname1, \n","                  'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","model_file.SetContentFile(fname1)\n","model_file.Upload()\n","drive.CreateFile({'id': model_file.get('id')})\n","\n","y_pred = model.predict_classes(x=X_test, batch_size=None, verbose=0, steps=None)\n","y_test = np.argmax(y_test, 1)\n","\n","class_names = ['Male', 'Female']\n","\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Gender Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Gender Normalized confusion matrix')\n","\n","plt.show()\n","print(\"\\nelapsed_time = \", (time.time() - start_time)/60, \" minutes\")\n","\n","# References:\n","#     [1] Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n","#     [2] https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CH1l0a7qkCl_","colab_type":"code","colab":{}},"cell_type":"code","source":["#[3]\n","# Age Classifier with stratified Kfold cross validation for Adience Benchmark\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def stratified_sampling(X, y, test_size, random_state):\n","    # apply Scikit stratified sampling\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n","    for train_index, test_index in sss.split(X, y):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","    return X_train, X_test, y_train, y_test\n","  \n","print(\"###############<< Age Classifier >>###############\\n\")\n","start_time = time.time()\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","print(\"Adience : 64 ===> Age classification\")\n","# Initialize GoogleDriveFile instance with file id.\n","\n","# data_file_64 = drive.CreateFile({'id': '1BE5HdE_mYkd6XjJ7e_pY6m3nfGaRZ87_'})\n","# data_file_64.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_128 = drive.CreateFile({'id': '1Tsf7XwB09dUZVXSmlO81Fw3lumUnRiNb'})\n","# data_file_128.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_200 = drive.CreateFile({'id': '1hTnC0V1-P0sT-nLhl5JK7ETMpXdL9zgd'})\n","# data_file_200.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# load Adience data to be used for testing\n","train_data_64_adience = drive.CreateFile({'id': '1tYfWhBVc9iWKqd2Qgp1It5JmLg6PqPTj'})\n","train_data_64_adience.GetContentFile('Adience_train_data.mat') \n","test_data_64_adience = drive.CreateFile({'id': '1yvBD7UvYMybgeR4smEtLkxxDN8q8kdFo'})\n","test_data_64_adience.GetContentFile('Adience_test_data.mat')\n","\n","# train_data_128_adience = drive.CreateFile({'id': '17uW_i5i4QIsbka_QPE424B2OyZgKE7jV'})\n","# train_data_128_adience.GetContentFile('Adience_train_data.mat') \n","# test_data_128_adience = drive.CreateFile({'id': '1nFm9J_rmZpI6ToVBeLrp1GPgXWVnamZT'})\n","# test_data_128_adience.GetContentFile('Adience_test_data.mat') \n","\n","num_cats = 8 # number of age categories (0, 4), [4, 8), [8, 15), [15, 25), [25, 38), [38, 48), [48, 60), 60+\n","sz = 64     # image dimension\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","train_data = scipy.io.loadmat('Adience_train_data')\n","test_data = scipy.io.loadmat('Adience_test_data')\n","X = train_data['X']\n","y = train_data['y_age'][0]\n","X_test = test_data['X']\n","y_test = test_data['y_age'][0]\n","\n","input_shape = (sz, sz, 3)\n","y_test = np_utils.to_categorical(y_test, num_cats)\n","\n","print(\"Train size = \", y.shape[0]) \n","print(\"Test size = \", y_test.shape[0])\n","\n","print('=========<< [3] Model build & train >>=========')\n","\n","# create model\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","model = Sequential()\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","# print(model.summary())\n","\n","# # load weigts trained on a previus training session\n","# last_weight_file = drive.CreateFile({'id': '1-2AueMt5zJ9OMA-pgETHZExlA5s0cCzI'}) # age\n","# last_weight_file.GetContentFile('last_weights.mat')\n","# model.load_weights('last_weights.mat')\n","\n","# Compile model\n","model.compile(optimizer=SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# define 10-fold cross validation\n","kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=37)\n","cvscores = []\n","\n","# loop over folds and aggregate metrics\n","fold_ctr = 1\n","for train, vald in kfold.split(X, y):\n","  y1 = np_utils.to_categorical(y, num_cats)\n","  # Fit the model\n","  model.fit(X[train], y1[train], epochs=2, batch_size=30, verbose=0)\n","\n","  # evaluate the model\n","  scores = model.evaluate(X[vald], y1[vald], verbose=0)\n","  print(\"Fold:%d  %s: %.2f%%\" % (fold_ctr, model.metrics_names[1], scores[1]*100))\n","  fold_ctr = fold_ctr + 1\n","  cvscores.append(scores[1] * 100)\n","  \n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","\n","print('=========<< [4] Predict >>=========')\n","\n","predictions = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","y_pred = model.predict_classes(x=X_test, batch_size=None, verbose=0, steps=None)\n","y_test = np.argmax(y_test, 1)\n","\n","print(\"\\nelapsed_time = \", (time.time() - start_time)/60, \" minutes\")\n","\n","# Compute confusion matrix\n","# class_names = ['0-3', '4-7', '8-14', '15-24', '25-37', '38-47', '48-59', '60-']\n","class_names = ['Male', 'Female']\n","cnf_matrix = confusion_matrix(y_test, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Age Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Age Normalized confusion matrix')\n","\n","plt.show()\n","\n","# Save Keras ModelCheckpoints on google drive\n","\n","# save model weights\n","id_64 = '1adEZUwik9dqAcAtyRp3nhjn2um93LGdr'\n","id_128 = '1ue4YR7spae8QqpCqB9JwHEMEArYS1nQf'\n","\n","fname = 'model_weights_age_strat_Kfold.h5'\n","model.save_weights(fname)\n","weights_file_aug = drive.CreateFile({'title' : fname, \n","                   'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","weights_file_aug.SetContentFile(fname)\n","weights_file_aug.Upload()\n","drive.CreateFile({'id': weights_file_aug.get('id')})\n","\n","# save whole model (architecture + weights + optimizer state)\n","fname1 = 'model_age_stratified_Kfold.h5'\n","model.save(fname1)\n","model_file = drive.CreateFile({'title' : fname1, \n","                  'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","model_file.SetContentFile(fname1)\n","model_file.Upload()\n","drive.CreateFile({'id': model_file.get('id')})\n","\n","# References:\n","#     [1] Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n","#     [2] https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4VEIfVXEtoSl","colab_type":"code","colab":{}},"cell_type":"code","source":["# [4]\n","# Age Classifier, Data augmentation, Data generator, stratified sampling\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","import time\n","\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from sklearn.metrics import confusion_matrix\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def stratified_sampling(X, y, test_size, random_state):\n","\n","    # apply Scikit stratified sampling\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n","    for train_index, test_index in sss.split(X, y):\n","      X_train, X_test = X[train_index], X[test_index]\n","      y_train, y_test = y[train_index], y[test_index]\n","\n","    return X_train, X_test, y_train, y_test\n","  \n","print(\"###############<< Age Classifier >>###############\\n\")\n","start_time = time.time()\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","\n","# Initialize GoogleDriveFile instance with file id.\n","\n","data_file_64 = drive.CreateFile({'id': '1BE5HdE_mYkd6XjJ7e_pY6m3nfGaRZ87_'})\n","data_file_64.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_128 = drive.CreateFile({'id': '1Tsf7XwB09dUZVXSmlO81Fw3lumUnRiNb'})\n","# data_file_128.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# data_file_200 = drive.CreateFile({'id': '1hTnC0V1-P0sT-nLhl5JK7ETMpXdL9zgd'})\n","# data_file_200.GetContentFile('UTKdata.mat') # Download file as 'UTKdata.mat'.\n","\n","# train_data_128_adience = drive.CreateFile({'id': '17uW_i5i4QIsbka_QPE424B2OyZgKE7jV'})\n","# train_data_128_adience.GetContentFile('Adience_train_data.mat') \n","\n","# test_data_128_adience = drive.CreateFile({'id': '1nFm9J_rmZpI6ToVBeLrp1GPgXWVnamZT'})\n","# test_data_128_adience.GetContentFile('Adience_test_data.mat') \n","\n","num_cats = 8 # number of age categories (0, 4), [4, 8), [8, 15), [15, 25), [25, 38), [38, 48), [48, 60), 60+\n","sz = 64     # image dimension\n","epochs=40\n","\n","data = scipy.io.loadmat('UTKdata')\n","X = data['X']\n","y_age = data['y_age'][0]\n","y_age = np_utils.to_categorical(y_age, num_cats)\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","y = y_age\n","\n","input_shape = (sz, sz, 3)\n","\n","test_ratio, vald_ratio = 0.15, 0.10\n","train_batch_size = 30\n","\n","X_train, X_test, y_train, y_test = stratified_sampling(X, y, test_size=test_ratio, random_state=37)\n","X_train, X_vald, y_train, y_vald = stratified_sampling(X_train, y_train, test_size=vald_ratio, random_state=37)\n","print(\"Train size = \", y_train.shape[0]) \n","print(\"Validation size = \", y_vald.shape[0])\n","print(\"Test size = \", y_test.shape[0])\n","\n","print('=========<< [3] Data augmentation and batch generation >>=========')\n","\n","vald_batch_size = int(train_batch_size*vald_ratio)\n","test_batch_size = int(train_batch_size*test_ratio)\n","\n","# data augmentation\n","datagen = ImageDataGenerator( featurewise_center=True,\n","                              featurewise_std_normalization=True,\n","                              rotation_range=20,\n","                              width_shift_range=0.2,\n","                              height_shift_range=0.2,\n","                              horizontal_flip=True)\n","datagen.fit(X_train)\n","# datagen = ImageDataGenerator()\n","\n","train_batches = datagen.flow(x=X_train, y=y_train, batch_size=train_batch_size)\n","vald_batches = datagen.flow(x=X_vald, y=y_vald, batch_size=vald_batch_size)\n","test_batches = datagen.flow(x=X_test, y=y_test, batch_size=test_batch_size)\n","\n","# build, compile and train the model\n","print('=========<< [4] Model build & train >>=========')\n","\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","\n","model = Sequential()\n","\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","\n","# print(model.summary())\n","\n","model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# last_weight_file = drive.CreateFile({'id': '1QRUpGK-kEbw1zylZhpEjXx-ApxBw3LGA'}) # age\n","# last_weight_file.GetContentFile('last_weights.mat')\n","# model.load_weights('last_weights.mat')\n","\n","steps_per_epoch = math.ceil( len(X_train) / (train_batch_size) )\n","vald_steps = math.ceil( len(X_vald) / vald_batch_size )\n","\n","train_vald_res = model.fit_generator(   generator=train_batches,\n","                                        steps_per_epoch=steps_per_epoch,\n","                                        validation_data=vald_batches,\n","                                        validation_steps=vald_steps,\n","                                        epochs=epochs,\n","                                        verbose=2)\n","print(train_vald_res)\n","print('=========<< [5] Predict >>=========')\n","\n","predictions = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","# Save Keras ModelCheckpoints on google drive\n","\n","# save model weights\n","id_64 = '1HQ2-ZE4wmY6KHy5DRHLAsEw-R4UyjgmV'\n","id_128 = '1nkk_tv_e4aVM_DXS5152smOm3vN55ZZZ'\n","\n","fname = 'model_weights_age.h5'\n","model.save_weights(fname)\n","weights_file_aug = drive.CreateFile({'title' : fname, \n","                   'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","weights_file_aug.SetContentFile(fname)\n","weights_file_aug.Upload()\n","drive.CreateFile({'id': weights_file_aug.get('id')})\n","\n","# save whole model (architecture + weights + optimizer state)\n","fname1 = 'model_age.h5'\n","model.save(fname1)\n","model_file = drive.CreateFile({'title' : fname1, \n","                  'parents': [{'kind': 'drive#fileLink', 'id': id_64}]})\n","\n","model_file.SetContentFile(fname1)\n","model_file.Upload()\n","drive.CreateFile({'id': model_file.get('id')})\n","\n","y_pred = model.predict_classes(x=X_test, batch_size=None, verbose=0, steps=None)\n","y_test = np.argmax(y_test, 1)\n","\n","class_names = ['0-3', '4-7', '8-14', '15-24', '25-37', '38-47', '48-59', '60-']\n","\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Age Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Age Normalized confusion matrix')\n","\n","plt.show()\n","\n","print(\"\\nelapsed_time = \", (time.time() - start_time)/60, \" minutes\")\n","\n","# Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011."],"execution_count":0,"outputs":[]},{"metadata":{"id":"OVrVgLxkzUoy","colab_type":"code","colab":{}},"cell_type":"code","source":["# [5]\n","# Age Classifier, random split\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","from keras.models import Sequential\n","from keras.optimizers import Adam, SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import h5py\n","  \n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","print(\"###############<< Age Classifier >>###############\\n\")\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","\n","# Initialize GoogleDriveFile instance with file id.\n","\n","# data_file_64 = drive.CreateFile({'id': '1l-v3-P-3yncMIg8EJ5EuZWgGDR_QR_Mj'})\n","# data_file_64.GetContentFile('UTKdata.mat')                                    # Download file as 'UTKdata.mat'.\n","\n","data_file_128 = drive.CreateFile({'id': '1cU4oHHsRnH2mE2R3tykEQ1gnAWBX3475'})\n","data_file_128.GetContentFile('UTKdata.mat')                                   # Download file as 'UTKdata.mat'.\n","\n","# data_file_224 = drive.CreateFile({'id': '1WZM8pWCNO1MLkmomGuwaHjxOrb5MGmO0'})\n","# data_file_224.GetContentFile('UTKdata.mat')                                 # Download file as 'UTKdata.mat'.\n","\n","# print('title: %s\\n' % (data_file_128['title']))\n","\n","num_cats = 8 # number of age categories (0, 4), [4, 8), [8, 15), [15, 25), [25, 38), [38, 48), [48, 60), 60+\n","sz = 128     # image dimension\n","epochs=10\n","\n","data = scipy.io.loadmat('UTKdata')\n","X = data['X']\n","y_age = data['y_age'][0]\n","y_age = np_utils.to_categorical(y_age, num_cats)\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","y = y_age\n","\n","input_shape = (sz, sz, 3)\n","\n","test_vald_ratio = 0.20\n","test_ratio, vald_ratio = 0.10, 0.10\n","train_batch_size = 30\n","\n","X_train, X_test_vald, y_train, y_test_vald = train_test_split(X, y, test_size=test_vald_ratio, random_state=37)\n","X_vald, X_test, y_vald, y_test = train_test_split(X_test_vald, y_test_vald, test_size = 0.50, random_state=37)\n","\n","print('=========<< [3] Data augmentation and batch generation >>=========')\n","\n","vald_batch_size = int(train_batch_size*vald_ratio)\n","test_batch_size = int(train_batch_size*test_ratio)\n","\n","# data augmentation\n","# datagen = ImageDataGenerator( featurewise_center=True,\n","#                               featurewise_std_normalization=True,\n","#                               rotation_range=20,\n","#                               width_shift_range=0.2,\n","#                               height_shift_range=0.2,\n","#                               horizontal_flip=True)\n","# datagen.fit(X_train)\n","\n","datagen = ImageDataGenerator()\n","train_batches = datagen.flow(x=X_train, y=y_train, batch_size=train_batch_size)\n","vald_batches =datagen.flow(x=X_vald, y=y_vald, batch_size=vald_batch_size)\n","test_batches = datagen.flow(x=X_test, y=y_test, batch_size=test_batch_size)\n","\n","# build, compile and train the model\n","print('=========<< [4] Model build & train >>=========')\n","\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","\n","model = Sequential()\n","\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","\n","print(model.summary())\n","model.compile(optimizer=SGD(lr=0.0001),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","last_weight_file = drive.CreateFile({'id': '1Tsu1ogHumh1HHE8pTjl37nhtoqAWf_7P'}) # age\n","last_weight_file.GetContentFile('last_weights.mat')\n","model.load_weights('last_weights.mat')\n","\n","steps_per_epoch = math.ceil( len(X_train) / (train_batch_size) )\n","vald_steps = math.ceil( len(X_vald) / vald_batch_size )\n","\n","train_vald_res = model.fit_generator(   generator=train_batches,\n","                                        steps_per_epoch=steps_per_epoch,\n","                                        validation_data=vald_batches,\n","                                        validation_steps=vald_steps,\n","                                        epochs=epochs,\n","                                        verbose=2)\n","print(train_vald_res)\n","print('=========<< [5] Predict >>=========')\n","\n","predictions = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","# Save Keras ModelCheckpoints on google drive\n","\n","# fname = 'model_64_weights_aug_age.h5'\n","# model.save_weights(fname)\n","# weights_file_aug = drive.CreateFile({'title' : fname,\n","#                     'parents': [{'kind': 'drive#fileLink', 'id': '1tQbF4hNKhher8BnnUWq9YaoIovjoZM6E'}] })\n","\n","fname = 'model_128_weights_age.h5'\n","model.save_weights(fname)\n","weights_file_aug = drive.CreateFile({'title' : fname,\n","                    'parents': [{'kind': 'drive#fileLink', 'id': '109-8ppwvlItSn8U-UuCgSRjNEu799ETG'}] })\n","\n","weights_file_aug.SetContentFile(fname)\n","weights_file_aug.Upload()\n","# print('Uploaded file with ID {}'.format(weights_file_aug.get('id')))\n","drive.CreateFile({  'id': weights_file_aug.get('id')})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i0mbEjLHVGF4","colab_type":"code","colab":{}},"cell_type":"code","source":["# [6]\n","# testing the trained model on different data set\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix\n","from keras.models import load_model\n","from keras.utils import np_utils\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","num_cats = 8\n","\n","# load Adience data to be used for testing\n","# train_data_64_adience = drive.CreateFile({'id': '1tYfWhBVc9iWKqd2Qgp1It5JmLg6PqPTj'})\n","# train_data_64_adience.GetContentFile('Adience_train_data.mat') \n","test_data_64_adience = drive.CreateFile({'id': '1yvBD7UvYMybgeR4smEtLkxxDN8q8kdFo'})\n","test_data_64_adience.GetContentFile('Adience_test_data.mat')\n","\n","# train_data_128_adience = drive.CreateFile({'id': '17uW_i5i4QIsbka_QPE424B2OyZgKE7jV'})\n","# train_data_128_adience.GetContentFile('Adience_train_data.mat') \n","# test_data_128_adience = drive.CreateFile({'id': '1nFm9J_rmZpI6ToVBeLrp1GPgXWVnamZT'})\n","# test_data_128_adience.GetContentFile('Adience_test_data.mat') \n","\n","# dataAd_train = scipy.io.loadmat('Adience_train_data')\n","dataAd_test = scipy.io.loadmat('Adience_test_data')\n","\n","# X1 = dataAd_train['X']\n","# y1_age = dataAd_train['y_age'][0]\n","# y1_age_cat = np_utils.to_categorical(y1_age, num_cats)\n","\n","X2 = dataAd_test['X']\n","y2_age = dataAd_test['y_age'][0]\n","y2_age_cat = np_utils.to_categorical(y2_age, num_cats)\n","\n","# returns a compiled model\n","last_model_file = drive.CreateFile({'id': '1Y9LwSYXUBEEx4DunWPRzDX3Jnq7MKw0W'}) # age (64, 64, 3)\n","last_model_file.GetContentFile('last_model.h5')\n","model = load_model('last_model.h5')\n","\n","predictions = model.evaluate(x=X2, y=y2_age_cat, verbose=2)\n","print(\"test_loss = \", predictions[0], \" test_accuracy = \", predictions[1])\n","\n","y_pred = model.predict_classes(x=X2, batch_size=None, verbose=0, steps=None)\n","\n","class_names = ['0-3', '4-7', '8-14', '15-24', '25-37', '38-47', '48-59', '60-']\n","\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y2_age, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Age Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Age Normalized confusion matrix')\n","\n","plt.show()\n","\n","# Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BtOwry-A5ceG","colab_type":"code","colab":{}},"cell_type":"code","source":["# [7]\n","# Age Classifier, combined datasets (Not implemented)\n","!pip install -U -q PyDrive\n","  \n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from google.colab import files\n","from oauth2client.client import GoogleCredentials\n","\n","import keras\n","import math\n","import scipy.io\n","import numpy as np\n","import h5py\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","from keras.models import Sequential\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    \n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","print(\"###############<< Age Classifier >>###############\\n\")\n","\n","print(\"=========<< [1] Retrieving Data >>=========\")\n","\n","# Initialize GoogleDriveFile instance with file id.\n","\n","data_utk = drive.CreateFile({'id': '1BE5HdE_mYkd6XjJ7e_pY6m3nfGaRZ87_'})\n","data_utk.GetContentFile('UTK_data.mat')\n","\n","train_data_adience = drive.CreateFile({'id': '1tYfWhBVc9iWKqd2Qgp1It5JmLg6PqPTj'})\n","train_data_adience.GetContentFile('Adience_train_data.mat') \n","\n","test_data_adience = drive.CreateFile({'id': '1yvBD7UvYMybgeR4smEtLkxxDN8q8kdFo'})\n","test_data_adience.GetContentFile('Adience_test_data.mat')\n","\n","num_cats = 8 # number of age categories (0, 4), [4, 8), [8, 15), [15, 25), [25, 38), [38, 48), [48, 60), 60+\n","sz = 64     # image dimension\n","epochs=1\n","\n","dataUTK = scipy.io.loadmat('UTK_data')\n","dataAd_train = scipy.io.loadmat('Adience_train_data')\n","dataAd_test = scipy.io.loadmat('Adience_test_data')\n","\n","X = dataUTK['X']\n","y_age = dataUTK['y_age'][0]\n","y_age = np_utils.to_categorical(y_age, num_cats)\n","\n","X1 = dataAd_train['X']\n","y1_age = dataAd_train['y_age'][0]\n","y1_age = np_utils.to_categorical(y1_age, num_cats)\n","\n","X2 = dataAd_test['X']\n","y2_age = dataAd_test['y_age'][0]\n","y2_age = np_utils.to_categorical(y2_age, num_cats)\n","\n","print('=========<< [2] Splitting data into train, validate & test >>=========')\n","\n","y = y_age\n","\n","input_shape = (sz, sz, 3)\n","\n","test_ratio, vald_ratio = 0.15, 0.10\n","train_batch_size = 50\n","\n","# extract testing data from UTK data \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=37)\n","\n","# concatenate UTK and Adience test data\n","X_test = np.concatenate([X_test, X2])\n","y_test = np.concatenate([y_test, y2_age])\n","\n","# concatenate UTK and Adience train data\n","X_train = np.concatenate([X_train, X1])           \n","y_train = np.concatenate([y_train, y1_age])\n","\n","# extract validation data from combined train data\n","X_train, X_vald, y_train, y_vald = train_test_split(X_train, y_train, test_size = vald_ratio, random_state=37)\n","\n","print('=========<< [3] Data augmentation and batch generation >>=========')\n","\n","vald_batch_size = int(train_batch_size*vald_ratio)\n","test_batch_size = int(train_batch_size*test_ratio)\n","\n","# data augmentation\n","datagen = ImageDataGenerator( featurewise_center=True,\n","                              featurewise_std_normalization=True,\n","                              rotation_range=20,\n","                              width_shift_range=0.2,\n","                              height_shift_range=0.2,\n","                              horizontal_flip=True)\n","datagen.fit(X_train)\n","\n","# datagen = ImageDataGenerator()\n","train_batches = datagen.flow(x=X_train, y=y_train, batch_size=train_batch_size)\n","vald_batches = datagen.flow(x=X_vald, y=y_vald, batch_size=vald_batch_size)\n","test_batches = datagen.flow(x=X_test, y=y_test, batch_size=test_batch_size)\n","\n","# build, compile and train the model\n","print('=========<< [4] Model build & train >>=========')\n","\n","vgg16_model = keras.applications.vgg16.VGG16(input_shape=input_shape, weights=None, classes=num_cats)\n","\n","model = Sequential()\n","\n","for new_layer in vgg16_model.layers:\n","    model.add(new_layer)\n","\n","print(model.summary())\n","model.compile(optimizer=SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","# last_weight_file = drive.CreateFile({'id': '13UdI_LwEfrPDzn4NAIZnGnlne_Z5rJOo'}) # age\n","# last_weight_file.GetContentFile('last_weights.mat')\n","# model.load_weights('last_weights.mat')\n","\n","steps_per_epoch = math.ceil( len(X_train) / (train_batch_size) )\n","vald_steps = math.ceil( len(X_vald) / vald_batch_size )\n","\n","train_vald_res = model.fit_generator(   generator=train_batches,\n","                                        steps_per_epoch=steps_per_epoch,\n","                                        validation_data=vald_batches,\n","                                        validation_steps=vald_steps,\n","                                        epochs=epochs,\n","                                        verbose=2)\n","print(train_vald_res)\n","print('=========<< [5] Predict >>=========')\n","\n","eval = model.evaluate(x=X_test, y=y_test, verbose=2)\n","print(\"test_loss = \", eval[0], \" test_accuracy = \", eval[1])\n","\n","# # Save Keras ModelCheckpoints on google drive\n","# fname = 'model_128_weights_age.h5'\n","# model.save_weights(fname)\n","# weights_file_aug = drive.CreateFile({'title' : fname, \n","#                    'parents': [{'kind': 'drive#fileLink', 'id': '1FUSWSUXc3AYImqTsrZNmQJ0A9vJQb9GO'}]})\n","\n","# weights_file_aug.SetContentFile(fname)\n","# weights_file_aug.Upload()\n","# drive.CreateFile({'id': weights_file_aug.get('id')})\n","\n","y_pred = model.predict(x=X_test, batch_size=None, verbose=0, steps=None)\n","\n","y_test = np.argmax(y_test, 1)\n","\n","class_names = ['0-', '4-', '8-', '15-', '25-', '38-', '48-', '60-']\n","\n","# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, y_pred)\n","np.set_printoptions(precision=2)\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, title='Age Confusion matrix, without normalization')\n","\n","# Plot normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Age Normalized confusion matrix')\n","\n","plt.show()\n","\n","# Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011."],"execution_count":0,"outputs":[]}]}